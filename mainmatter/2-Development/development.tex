\chapter{Theorical Background}


\section{No Free Lunch Algorithm (NFL)}
The no free lunch theorem for search and optimization applies to finite spaces and algorithms that do not resample points. It states "All algorithms that search for an extrema of a cost function perform exactly the same when averaged over all possible cost functions." To increase the scope of NFL-like analyses, we need to make two slight extensions: first, we must broaden the definition of performance measures to allow for dependence on $f$-the list of multiple functions, and second, we need to generalize fitness functions to allow for nondeterminism. \cite{Wolpert2005}

The search problem in case of proteins can be thought to comprise of different sample spaces: Primary Structures, Secondary Structures, Evolutionary Structures, Chemical Parameters, Atomic Parameters etc. This work only tries to explore the primary, secondary and evolutionary nature of protein-residues.

\subsubsection{Generalized Optimization}

The major implication of \acrshort{nfl} is useful when the sample spaces are operated by different algorithms. The theorem being that all algorithms in different sample spaces produce the highest optimum results for a given problem. Generalized Optimization follows that when these different algorithms that are optimized in different sample spaces are included in one algorithm, then the method provides us the best predictions.


\section{Literature Review}

Finding the interaction between drugs and proteins based simply on their primary structure information is one of the many challenges faced in drug-synthesis process. The experimental methods are quite expensive in terms of time, money and resources. Still the mutation in cells are growing higher due to extensive use of chemical and electromagnetic radiations in our environment. In one hand, diseases are getting powerful and in the other hand, the experimental method can take months when finding a right cure is considered. One of the solutions to this is use of high computing ends that can automate some of its repetitive works. Therefore, computational methods help to lessen the amount of works required to find right drug partner for the evolving diseases.\cite{Leelananda2016}

Protein molecules are the workhorses of our body. For example: the blood protein hemoglobin is functional for $O_2$ /$CO_2$ transportation, antibodies defend against viruses and hormonal protein insulin regulates our blood sugar level. The protein has differences in structure, according to the desirable functional characteristics of our body. This structure is so important for our health, that understanding them can aid to cure diseases. For example, diseases like Parkinson’s is unrelated to bacteria/virus but due to incorrect folding of proteins. \cite{Keasar2018a} 
\iffalse So, modeling of protein structures is vital to interpret disease mechanisms and design new drug treatments. Modeling of protein requires protein contact prediction after which 3D models are generated using suitable software packages like CONFOLD suite. \fi

Our bodily functions are dependent on protein structure and their interdependent interactions play a vital role. Some of these proteins are of critical interest to biochemistry and biomedicine researchers.\cite{Astrand2019} For example, a protein known as amyloid beta, which forms plaques in the human brain, is a key to understanding Alzheimer's disease. Improving our understanding of correct protein structures can lead to the design of drug treatments that can target deactivation of proteins of interest. Also, the personalized treatment of any sick person by taking sample of protein structure may help design cure for specific cases (eg. due to mutation changes of protein structure), which otherwise is referred in for general case of differently related protein~\cite{Fout2017}.Thus it will solve issues of wrong medication hazards, which are the general scenario for the developing and under-developed countries.

The rise of new machine learning methods and deep-learning techniques are closing the gaps to create better predictions. The cure of evolving diseases can be computationally researched by use of knowledge-based community. The community contributed databases in drugs and protein sectors are growing at the same pace. Clearly, both the data resources and algorithmic techniques can help human community to counter-act against such circumstances.

In the field of bioinformatics, the long-standing problem of computationally predicting the structure of a protein remains unsolved\cite{Finkelstein2017b}. The key to solving this problem is to accurately predict 'contacts', which requires measuring the physical distances between the amino acids of a folded protein. The current state-of-the-art methods like ProC\_S3 and SVMcon are about 50\% accurate \cite{Adhikari2017}.		

Deep learning, which is a subfield of machine learning, has recently enabled accurate face recognition in Facebook, Google Photos etc. Google’s self driving car already uses automatic driving \cite{Becker2008}. It has also helped to accurately detect skin cancer. These demonstrated successes of deep learning algorithms clearly highlight its potential to greatly accelerate scientific problems such as protein contact prediction. 

In the other hand chemical properties of drugs and the targets complicate the situation as they react differently with slight change in protein sequence. While computational techniques have helped to simulate the different conditions, the fundamental dataset is still long way to go. The reason being that the identification of proteins structure can take months. Again the isomeric states of proteins' structures can have different functional aspects to the body physiology. Moreover, the complexes tend to behave similarly even when the protein sequences are distantly related, one of the results of tertiary structures that the proteins are form of. \cite{Choudhuri2014}

The deep learning methods are quite good at predicting the molecular behaviour of the drug. However they present no good means when predicting the behaviour of proteins. This can be thought as protein-folding problem which when solved will help escalate the development of treatment facilites around the globe. The \acrfull{casp} experiments is such community which holds competition to determine and advance the state of art in modeling the protein sequence from amino acids.\cite{Gooch2011} To find the computational measure to predict the drug for a given protein, the major fallback is that the simple encoding techniques don’t incorporate the proteins behaviour related to hydrophobicity, acidity, secondary and tertiary structures information.\cite{Wong2018}

The problem formulation of protein-drug interaction categorizes the efficiency of protein-interaction prediction method. The methods based on binary classification has high accuracy, but has a big bias problem. This is because the unidentified interactions are also regarded as non-interactive pairs. \cite{Mahato2016,Tang2013}. The dataset is quite resourceful in case of classification problem. However, due to disadvantages of misclassification and same classification value for low-interactive and highly-interactive protein-drug pairs, regression problem is the better modificatiion of problem situation. \cite{Tang2013}

No Free Lunch Theorem \cite{Wolpert2005} on the other hand works by basing the prediction guesses based on a number of domain representations. The domain representations of input data is solved using multiple functions to get the domain specific abilities of problem situation. Here, we use the sequence information of proteins to calculate the predictions on different feature transformation techniques and generalize those predictions using a stack of dense layers.
